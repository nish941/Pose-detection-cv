
## Human Movement and Pose Recognition using OpenCV

````markdown
# ğŸ•º Human Pose Detection & Movement Recognition

> A real-time pose estimation pipeline using OpenCV and keypoint tracking â€” built as a self-driven computer vision project during my 5th semester to understand the dynamics of body motion, alignment, and classification.

---

## ğŸ“Œ About the Project

This project started as a personal experiment during my **Computer Vision coursework** in Fall 2024. I wanted to go beyond static image detection and dive into how machines perceive human movement in live video.

I explored real-time **pose detection** using OpenCV and MediaPipe, mapped **keypoints to skeletal structures**, and then layered on **posture classification** logic based on joint angles and body orientation.

After several weekends of debugging laggy video feeds and weird arm angles, I finally got a working system that tracks skeletons, analyzes motion patterns, and classifies body activity with reasonable accuracy â€” all on medium-spec laptops at ~30 FPS.

---

## ğŸ¯ What I Set Out to Build

- Detect human body pose in real-time using keypoint tracking
- Build a skeleton structure from keypoints
- Track temporal movement patterns
- Align and normalize poses across frames
- Classify activities like "standing", "sitting", "walking", etc.
- Deploy a lightweight app to test on different devices

---

## âœ… What I Achieved

- ğŸ“¸ Pose detection using **MediaPipe + OpenCV**
- ğŸ§ Keypoint-to-skeleton mapping and tracking
- ğŸ§  Implemented **motion vector analysis** for temporal tracking
- ğŸ§¬ **Affine alignment** to standardize poses across scale and angle
- âš™ï¸ Achieved **92.4% keypoint accuracy**
- ğŸ–¥ï¸ Real-time performance at **30 FPS** on a basic laptop
- ğŸŒ Deployed frontend to **GitHub Pages** for live testing
- ğŸ§ª Created activity classifier (rule-based prototype) for posture labeling

---

## ğŸ” Technical Details

- Used **MediaPipe Pose** to extract 33 body landmarks in real-time
- Extracted joint angles (e.g. elbow, knee) using `arccos(dot product)`
- Applied **affine transformation** to normalize skeleton position/scale
- Used **vector movement** of joints across frames to detect motion patterns
- Designed rule-based classifier for simple actions:
  - If knee angles < threshold â†’ "Sitting"
  - If head/torso position oscillates â†’ "Walking"
- Optimized for real-time detection (video buffer + FPS limiter)
- Built using pure Python and OpenCV, no GPU dependencies

---

## ğŸ› ï¸ Tech Stack

| Purpose            | Tools Used                              |
|--------------------|------------------------------------------|
| ğŸ’» Language         | Python                                   |
| ğŸ‘ï¸ CV & Detection   | OpenCV, MediaPipe                        |
| ğŸ“Š Visualization    | Matplotlib, Skeleton Overlay             |
| ğŸŒ Frontend         | HTML, CSS, JS                            |
| ğŸ–¥ Hosting (UI)     | GitHub Pages                             |

---

## ğŸ“ File Structure

```bash
ğŸ“¦Pose-detection-cv
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ pose_estimator.py        # Keypoint extraction and processing
â”‚   â”œâ”€â”€ classifier.py            # Simple rule-based activity classifier
â”‚   â”œâ”€â”€ visualizer.py            # Draw skeleton overlays
â”‚   â””â”€â”€ video_stream.py          # Capture video, run main loop
â”œâ”€â”€ ğŸ“‚ frontend/
â”‚   â”œâ”€â”€ index.html               # Web UI with info
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ ğŸ“‚ sample_videos/            # Demo clips
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.py                       # Main entry point
````

---

## ğŸŒ Try It Live

> âš¡ Web Interface & Overview:
> [ğŸ”— Live Pose Estimation Frontend](https://nish941.github.io/Pose-detection-cv)

âš ï¸ Live webcam detection must be run locally due to browser security â€” but you can see **video samples**, **classification examples**, and project logic here.

---

## ğŸ§ª Example Outputs

* âœ… Skeletons with joint overlay and landmark labels
* ğŸ” Temporal pose smoothing across frames
* ğŸ§  Classifications: `"Standing"`, `"Sitting"`, `"Walking"` based on limb angles and keypoint shifts

*(Screenshots omitted for now â€” coming soon!)*

---

## ğŸš€ Run Locally (Real-Time Detection)

### 1. Clone and Install

```bash
git clone https://github.com/nish941/Pose-detection-cv.git
cd Pose-detection-cv
pip install -r requirements.txt
```

### 2. Run the Pose Detector

```bash
python run.py
```

Make sure your webcam is active. Skeleton should appear on-screen with live classification.

---

## ğŸ§  Learning Outcomes

* Understood how **2D keypoints â†’ postural logic** works in real-time
* Applied vector math + OpenCV transformations to analyze motion
* Gained hands-on experience with **temporal smoothing, affine alignment**, and skeleton tracking
* Learned to manage **video stream buffers** and ensure high FPS

---

## ğŸ”® Future Improvements

* Replace rule-based classifier with a small LSTM model (pose â†’ action)
* Add **multi-person tracking** (currently 1-person only)
* Integrate body-part velocity tracking
* Export final pose sequences as JSON for external use (e.g., games, physical therapy)

---

## ğŸ™ Acknowledgements

* [Google MediaPipe](https://mediapipe.dev/) for pose landmark detection
* OpenCV Docs and CVZone tutorials
* Friends who volunteered to walk, sit, and wave at my webcam during testing ğŸ™ƒ

  
